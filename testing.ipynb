{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a56878d-9312-48e6-ba35-045ef519c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import RFE\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn .metrics import roc_auc_score\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76276a78",
   "metadata": {},
   "source": [
    "f_orgnl - best 12, th=0.435: 0.6993865030674846; rf (): 0.7310657596371882; best k-nn (33): 0.6229326513213981\n",
    "f_op_1 - best : ; rf: ; best k-nn (): \n",
    "f_op_2 - best : ; rf: ; best k-nn (): \n",
    "f_op_3 - best : ; rf: ; best k-nn (): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097a1a22-e4d6-4ac5-b01f-83f60a4bfd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "sti_features = 'train_75_people_data.csv'\n",
    "#sti_features ='features_optimized_1.csv'\n",
    "#sti_features ='features_optimized_2.csv'\n",
    "#sti_features ='features_optimized_3.csv'\n",
    "\n",
    "data = pd.read_csv(sti_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e24d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Field for creating models (and saving them)\n",
    "\n",
    "def create_knn(x,y,dims,neighbors):\n",
    "    pca = PCA(n_components=dims)\n",
    "    pca_component = pca.fit_transform(x)\n",
    "    final_model = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "    final_model.fit(pca_component, y)\n",
    "    pickle.dump(final_model,open(f'knn{neighbors}_{dims}_model.pkl', 'wb'))\n",
    "    pickle.dump(pca,open(f'pca{dims}.pkl', 'wb'))\n",
    "\n",
    "def create_rf(x,y,n_trees,depth):\n",
    "    final_model = RandomForestClassifier(n_estimators=n_trees, max_depth=depth, bootstrap=True)\n",
    "    final_model.fit(x, y)\n",
    "    pickle.dump(final_model,open(f'rf{n_trees}_{depth}_model.pkl', 'wb'))\n",
    "\n",
    "X = data[['H_value', 'S_value', 'V_value', 'red_presence', 'brown_presence', 'blue_presence', 'pink_presence', 'white_presence','black_presence','atypical_pigment_network', 'blue-white_veil', 'asymmetry_values']]\n",
    "y=data['cancer_or_not']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.T).T\n",
    "\n",
    "create_knn(X_scaled,y,3,24)\n",
    "create_rf(X_scaled,y,71,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8110409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for log: \n",
      "accuracy: 0.7008196721311475\n",
      "recall: 0.7986111111111112\n",
      "auc:0.7231944444444445\n",
      "Now preforming a sampling test sampling 1000 times\n",
      "standard deviation for accuracy 0.02887956263484073\n",
      "mean accuracy  0.7001475409836065\n",
      "standard deviation for recall 0.03302622925312891\n",
      "mean recall 0.7979714821277841\n",
      "\n",
      "Test for rf: \n",
      "accuracy: 0.7336065573770492\n",
      "recall: 0.8472222222222222\n",
      "auc:0.7728472222222221\n",
      "Now preforming a sampling test sampling 1000 times\n",
      "standard deviation for accuracy 0.029632916966176887\n",
      "mean accuracy  0.7333770491803279\n",
      "standard deviation for recall 0.030072257928505514\n",
      "mean recall 0.8472586716826577\n",
      "\n",
      "Test for knn: \n",
      "accuracy: 0.6516393442622951\n",
      "recall: 0.7777777777777778\n",
      "auc:0.6859375\n",
      "Now preforming a sampling test sampling 1000 times\n",
      "standard deviation for accuracy 0.030368881275899526\n",
      "mean accuracy  0.6514262295081967\n",
      "standard deviation for recall 0.03497393022772075\n",
      "mean recall 0.7779123703018954\n",
      "\n",
      "Test for final model: \n",
      "accuracy: 0.7049180327868853\n",
      "recall: 0.8194444444444444\n",
      "auc:0.7273263888888889\n",
      "Now preforming a sampling test sampling 1000 times\n",
      "standard deviation for accuracy 0.029486785206437792\n",
      "mean accuracy  0.7062008196721311\n",
      "standard deviation for recall 0.030889672844207405\n",
      "mean recall 0.8208142893772321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Field for evaluating the final combined model\n",
    "\n",
    "def evaluate_model(y,predictions):\n",
    "    for k in range(len(predictions)):\n",
    "        predictions[k]=predictions[k]/len(predictions)\n",
    "\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    cancer = 0\n",
    "    not_cancer = 0\n",
    "\n",
    "    threshold_proba = 0.5\n",
    "\n",
    "    #Confusion matrix\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    auc_list=[]\n",
    "    for x in range(len(y)):\n",
    "        yes = 0\n",
    "        for k in range(len(predictions)):\n",
    "            yes+=predictions[k][x][1]\n",
    "        #yes =  pred_list_model_random_tree_proba_norm[x][1]+pred_list_model_knn_proba_norm[x][1]+pred_list_model_log_proba_norm[x][1]\n",
    "        if yes > threshold_proba:\n",
    "            cancer += 1\n",
    "            if 1 == y[x]:\n",
    "                TP += 1\n",
    "                correct += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "                wrong +=1\n",
    "        else:\n",
    "            not_cancer += 1\n",
    "            if 0 == y[x]:\n",
    "                TN += 1\n",
    "                correct += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "                wrong +=1\n",
    "    for k in range(len(predictions)):\n",
    "        auc_list.append(roc_auc_score(y,predictions[k][:,1]))\n",
    "    accuracy=correct/(correct+wrong)\n",
    "    recall=TP/(TP+FN)\n",
    "    auc=np.mean(auc_list)\n",
    "\n",
    "    d={\"acc\":accuracy,\"rec\":recall,\"auc\":auc}\n",
    "    return d\n",
    "\n",
    "def test(df_test_data,models):\n",
    "    X_test_data = df_test_data[['H_value', 'S_value', 'V_value', 'red_presence', 'brown_presence', 'blue_presence', 'pink_presence', 'white_presence','black_presence','atypical_pigment_network', 'blue-white_veil', 'asymmetry_values']]\n",
    "    y_test_data=df_test_data['cancer_or_not'].to_list()\n",
    "\n",
    "    X_scaled_test_data = scaler_reload.transform(X_test_data)\n",
    "\n",
    "    X_scaled_pca = pca_reload.transform(X_scaled_test_data)\n",
    "\n",
    "    predictions=[]\n",
    "    if 'log' in models:\n",
    "        predictions.append(model_log.predict_proba(X_scaled_test_data))\n",
    "    if 'rf' in models:\n",
    "        predictions.append(model_random_tree.predict_proba(X_scaled_test_data))\n",
    "    if 'knn' in models:\n",
    "        predictions.append(model_knn.predict_proba(X_scaled_pca))\n",
    "\n",
    "    d = evaluate_model(y_test_data,predictions)\n",
    "    return d\n",
    "\n",
    "def sampling_test(n,df_test_data_original,models=['log','rf','knn']):\n",
    "    print(f\"Now preforming a sampling test sampling {n} times\")\n",
    "    accuracies=[]\n",
    "    recalls=[]\n",
    "    samplesize=len(df_test_data_original)\n",
    "    for i in range(n):\n",
    "        df_test_data = df_test_data_original.sample(samplesize,replace=True)\n",
    "        d=test(df_test_data,models)\n",
    "        #df_test_data = df_test_data_original\n",
    "        \n",
    "        accuracies.append(d[\"acc\"])\n",
    "        recalls.append(d[\"rec\"])\n",
    "\n",
    "    print(\"standard deviation for accuracy\",statistics.stdev(accuracies))\n",
    "    print(\"mean accuracy \",statistics.mean(accuracies))\n",
    "    print(\"standard deviation for recall\",statistics.stdev(recalls))\n",
    "    print(\"mean recall\",statistics.mean(recalls))\n",
    "\n",
    "\n",
    "model_log = pd.read_pickle('./final_form_of_repository/models/groupR_log_regr_classifier.sav')\n",
    "model_random_tree = pd.read_pickle('./final_form_of_repository/models/groupR_random_forest_classifier.sav')\n",
    "model_knn = pd.read_pickle('./final_form_of_repository/models/groupR_knn_classifier.sav')\n",
    "pca_reload = pd.read_pickle('./final_form_of_repository/models/pca.sav')\n",
    "df_test_data_original = pd.read_csv('test_25_people_data.csv')\n",
    "scaler_reload, features = pd.read_pickle('./final_form_of_repository/models/scaler.sav')\n",
    "\n",
    "#models=['log','rf','knn']\n",
    "models=['log','rf','knn']\n",
    "for model in models:\n",
    "    print(f\"Test for {model}: \")\n",
    "    results=test(df_test_data_original,[model])\n",
    "    print(f'accuracy: {results[\"acc\"]}\\nrecall: {results[\"rec\"]}\\nauc:{results[\"auc\"]}')\n",
    "    sampling_test(1000,df_test_data_original,[model])\n",
    "    print()\n",
    "\n",
    "\n",
    "print(f\"Test for final model: \")\n",
    "results=test(df_test_data_original,models)\n",
    "print(f'accuracy: {results[\"acc\"]}\\nrecall: {results[\"rec\"]}\\nauc:{results[\"auc\"]}')\n",
    "sampling_test(1000,df_test_data_original,models)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a126c009",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "if len(sys.argv)==3:\n",
    "    img=sys.argv[1]\n",
    "    mask=sys.argv[2]\n",
    "    print(classify(img,mask))\n",
    "else:\n",
    "    print(\"No input\")\n",
    "    test_csv=pd.read_csv(\"../test_25_people_data.csv\")\n",
    "    filenames=test_csv[\"Name_Of_Picture\"].to_list()\n",
    "    y=test_csv[\"cancer_or_not\"].to_list()\n",
    "\n",
    "    imgs=os.listdir(\"../images\")\n",
    "    cancer_counter=0\n",
    "    all_counter=0\n",
    "    for i in range(len(filenames)):\n",
    "        \n",
    "        filename=filenames[i]\n",
    "        true_value=y[i]\n",
    "\n",
    "        print(i/len(filenames))\n",
    "\n",
    "        imgpath=\"../images/\"+filename+\".png\"\n",
    "        maskpath=\"../masks/\"+filename+\"_mask.png\"\n",
    "        if os.path.exists(maskpath):\n",
    "            cancer,prob=classify(imgpath,maskpath)\n",
    "            if cancer==true_value:\n",
    "                cancer_counter+=1\n",
    "            all_counter+=1\n",
    "        else:\n",
    "            print(\"nomask\")\n",
    "    print(\"Accuracy: \",cancer_counter/all_counter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37940a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for whatever\n",
    "\n",
    "# 0.10003239426876925\n",
    "# 0.06920752305228388\n",
    "'''\n",
    "n=len(pred_list_model_log_proba)\n",
    "confusion_matrix = np.matrix([[TN/(TN+FP), FP/(TN+FP)], [FN/(FN+TP), TP/(FN+TP)]])\n",
    "print('Correct:', correct, '    Wrong:', wrong, '    Cancer prediction:', cancer, '    Not cancer prediction:', not_cancer, '    Accuracy:', )\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix,display_labels=model_knn.classes_)\n",
    "disp.plot()\n",
    "print(TP/(TP+FN))\n",
    "#plt.savefig(\"final_confusion_matrix_prob_classes.png\")'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
